"""
File: app.py
Last Updated: October 29, 2025 - v10.2.15
Description: Main Flask application with complete news analysis, transcript checking, and YouTube features

CHANGES IN v10.2.15 (October 29, 2025):
========================
CRITICAL FIX: Debate Arena Route Redirect Issue
- ROOT CAUSE: /debate-arena route was redirecting to /simple-debate-arena
- ERROR: Users clicking "Debate Arena" menu were sent to old simple-debate-arena page
- SYMPTOMS: Menu link showed correct href="/debate-arena" but got redirected
- FIXED: Removed redirect logic from /debate-arena route (lines 345-350)
- FIXED: Now ALWAYS renders templates/debate-arena.html directly
- RESULT: /debate-arena now properly loads the new debate arena page!
- PRESERVED: All v10.2.14 functionality (DO NO HARM ‚úì)

CHANGES IN v10.2.14 (October 27, 2025):
========================
CRITICAL FIX: Response Key Mismatch - Frontend Not Displaying Services
- ROOT CAUSE: app.py returning 'results' key but frontend expects 'data' key  
- ERROR: Frontend receives success=True but can't find analysis data to display
- SYMPTOMS: No services shown, no analysis details, trust score missing, empty results
- FROM LOG: Response was 6734 bytes (too small), services not rendering
- ISSUE: Line 477 returns {'success': True, 'results': final_results}
- FRONTEND EXPECTS: {'success': True, 'data': final_results}  
- FIXED: Changed 'results' to 'data' on line 477
- RESULT: Frontend now correctly receives and displays all 7 services!
- RESULT: Trust scores, source info, author details all now visible!
- PRESERVED: All v10.2.13 functionality (DO NO HARM ‚úì)

TruthLens News Analyzer - Complete with Debate Arena & Live Streaming
Version: 10.2.15 - DEBATE ARENA ROUTE FIX
Date: October 29, 2025

This file is complete and ready to deploy to GitHub/Render.
Last modified: October 29, 2025 - v10.2.15 DEBATE ARENA ROUTE FIX
"""

import os
import re
import json
import time
import logging
import traceback
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from urllib.parse import urlparse
import requests
from bs4 import BeautifulSoup
from flask import Flask, render_template, request, jsonify, send_from_directory, Response
from flask_cors import CORS
from dotenv import load_dotenv

# CRITICAL IMPORTS FOR DATA TRANSFORMATION FIX
from services.news_analyzer import NewsAnalyzer
from services.data_transformer import DataTransformer

# YOUTUBE TRANSCRIPT EXTRACTION (v10.2.0)
from services.youtube_scraper import extract_youtube_transcript

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# FLASK APP INITIALIZATION
# ============================================================================
app = Flask(__name__, 
            static_folder='static',
            static_url_path='/static',
            template_folder='templates')
CORS(app)

# Set secret key for session management
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'your-secret-key-change-in-production')

logger.info("=" * 80)
logger.info("Flask app initialized with EXPLICIT static configuration:")
logger.info(f"  static_folder: {app.static_folder}")
logger.info(f"  static_url_path: {app.static_url_path}")
logger.info(f"  template_folder: {app.template_folder}")
logger.info("=" * 80)

# ============================================================================
# DATABASE CONFIGURATION FOR DEBATE ARENAS (v9.0.0 + v10.2.6)
# ============================================================================

database_url = os.getenv('DATABASE_URL')

if database_url:
    # Render uses 'postgres://' but SQLAlchemy needs 'postgresql://'
    if database_url.startswith('postgres://'):
        database_url = database_url.replace('postgres://', 'postgresql://', 1)
    
    app.config['SQLALCHEMY_DATABASE_URI'] = database_url
    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
    app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
        'pool_pre_ping': True,
        'pool_recycle': 300,
        'connect_args': {
            'connect_timeout': 10
        }
    }
    
    logger.info("=" * 80)
    logger.info("DATABASE CONFIGURATION:")
    logger.info("  ‚úì PostgreSQL configured for Debate Arenas")
    logger.info("  ‚úì Connection pooling enabled")
    logger.info("  ‚úì Auto-reconnect on failure")
    logger.info("=" * 80)
    
    # Initialize SQLAlchemy
    from flask_sqlalchemy import SQLAlchemy
    db = SQLAlchemy(app)
    
    # Import OLD debate models (optional - gracefully handle if missing)
    old_debate_available = False
    try:
        from debate_models import User, Debate, Argument, Vote
        logger.info("  ‚úì Old debate models imported successfully")
        old_debate_available = True
    except ImportError as e:
        logger.warning(f"  ‚ö† Old debate models not available: {e}")
        old_debate_available = False
    
    # Import SIMPLE debate system (v10.2.6) - SHARED DB INSTANCE (v10.2.9)
    simple_debate_available = False
    try:
        from simple_debate_models import init_simple_debate_db
        from simple_debate_routes import simple_debate_bp
        
        # CRITICAL v10.2.9 FIX: Pass shared db instance to simple debate system
        init_simple_debate_db(db)
        
        # Register the simple debate blueprint
        app.register_blueprint(simple_debate_bp)
        
        logger.info("  ‚úì Simple debate models initialized with shared db")
        logger.info("  ‚úì Simple debate routes registered")
        simple_debate_available = True
    except ImportError as e:
        logger.warning(f"  ‚ö† Simple debate system not available: {e}")
        simple_debate_available = False
    except Exception as e:
        logger.error(f"  ‚úó Simple debate initialization error: {e}")
        simple_debate_available = False
    
    # Create database tables if available
    if old_debate_available or simple_debate_available:
        with app.app_context():
            try:
                db.create_all()
                logger.info("  ‚úì Database tables created/verified")
                if old_debate_available:
                    logger.info("    - Old debate tables: users, debates, arguments, votes")
                if simple_debate_available:
                    logger.info("    - Simple debate tables: simple_debates, simple_arguments, simple_votes")
            except Exception as e:
                logger.error(f"  ‚úó Database initialization error: {e}")
                old_debate_available = False
                simple_debate_available = False
    else:
        logger.warning("  ‚ö† No debate models available - debate features disabled")
        db = None
else:
    db = None
    old_debate_available = False
    simple_debate_available = False
    logger.info("=" * 80)
    logger.info("DATABASE: Not configured (All Debate Arenas disabled)")
    logger.info("=" * 80)

# ============================================================================
# INITIALIZE SERVICES
# ============================================================================

news_analyzer_service = NewsAnalyzer()
data_transformer = DataTransformer()

logger.info("=" * 80)
logger.info("NEWS ANALYZER SERVICE INITIALIZATION:")
logger.info(f"  ‚úì NewsAnalyzer initialized")
logger.info(f"  ‚úì DataTransformer initialized")
logger.info(f"  ‚úì Ready to process news articles")
logger.info("=" * 80)

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def extract_article_text(url: str) -> Tuple[Optional[str], Optional[Dict]]:
    """Extract article text and metadata from URL using Beautiful Soup."""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove unwanted elements
        for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside']):
            element.decompose()
        
        # Try to find the article title
        title = None
        for selector in ['h1', 'title', '[property="og:title"]', '.article-title']:
            title_elem = soup.select_one(selector)
            if title_elem:
                title = title_elem.get_text(strip=True)
                if title:
                    break
        
        # Try to find the publication date
        pub_date = None
        for selector in ['time', '[property="article:published_time"]', '.publish-date', '.date']:
            date_elem = soup.select_one(selector)
            if date_elem:
                pub_date = date_elem.get('datetime') or date_elem.get_text(strip=True)
                if pub_date:
                    break
        
        # Extract main article text
        article_text = []
        
        # Try common article selectors
        article_selectors = [
            'article',
            '[role="main"]',
            '.article-content',
            '.post-content',
            '.entry-content',
            'main'
        ]
        
        article_container = None
        for selector in article_selectors:
            article_container = soup.select_one(selector)
            if article_container:
                break
        
        if article_container:
            # Extract paragraphs from article
            paragraphs = article_container.find_all(['p', 'h2', 'h3'])
            for p in paragraphs:
                text = p.get_text(strip=True)
                if len(text) > 50:  # Filter out very short text
                    article_text.append(text)
        else:
            # Fallback: get all paragraphs
            paragraphs = soup.find_all('p')
            for p in paragraphs:
                text = p.get_text(strip=True)
                if len(text) > 50:
                    article_text.append(text)
        
        if not article_text:
            logger.warning(f"No substantial article text found for {url}")
            return None, None
        
        full_text = '\n\n'.join(article_text)
        
        metadata = {
            'url': url,
            'title': title,
            'publication_date': pub_date,
            'word_count': len(full_text.split())
        }
        
        return full_text, metadata
        
    except Exception as e:
        logger.error(f"Error extracting article from {url}: {e}")
        return None, None

def validate_url(url: str) -> bool:
    """Validate if a string is a valid URL."""
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False

# ============================================================================
# STATIC PAGE ROUTES
# ============================================================================

@app.route('/')
def index():
    """Main page - News Analysis"""
    return render_template('index.html')

@app.route('/transcript')
def transcript():
    """Transcript analysis page"""
    return render_template('transcript.html')

@app.route('/features')
def features():
    """Features page"""
    return render_template('features.html')

@app.route('/about')
def about():
    """About page"""
    return render_template('about.html')

@app.route('/contact')
def contact():
    """Contact page"""
    return render_template('contact.html')

@app.route('/live-stream')
def live_stream():
    """Live stream analysis page"""
    return render_template('live-stream.html')

@app.route('/debate-arena')
def debate_arena():
    """
    NEW Debate Arena page (v4.2.0 - Partner Mode, Pick-a-Fight, Live Voting)
    
    FIXED v10.2.15: Now ALWAYS renders debate-arena.html (no redirect)
    
    Features:
    - Partner Mode: Private debates with share codes
    - Pick-a-Fight: Public challenge system
    - Live Debates: Real-time voting with percentage display
    - Authentication: Email verification system
    - Arguments: 50-500 word limit with validation
    - My Debates: Track your participation
    """
    return render_template('debate-arena.html')

@app.route('/simple-debate-arena')
def simple_debate_arena():
    """
    OLD Simple Debate Arena page (v10.2.6 - anonymous, no authentication)
    
    NOTE: This is the OLD simple debate arena system.
    Users should use /debate-arena for the new system with more features.
    
    Features:
    - Pick a Fight: Create debate topic and first argument
    - Join a Fight: Add opposing argument to open debate
    - Judgement City: Vote on completed debates
    - Anonymous voting via browser fingerprint
    - 250-word argument limit
    - Real-time voting bar chart
    """
    if not simple_debate_available:
        # Return simple HTML error instead of requiring error.html template
        return '''
        <!DOCTYPE html>
        <html>
        <head>
            <title>Simple Debate Arena - Not Available</title>
            <style>
                body { font-family: Arial, sans-serif; padding: 40px; text-align: center; background: #f5f5f5; }
                .error-box { background: white; padding: 40px; border-radius: 12px; max-width: 600px; margin: 0 auto; box-shadow: 0 4px 12px rgba(0,0,0,0.1); }
                h1 { color: #dc2626; margin-bottom: 20px; }
                p { color: #666; line-height: 1.6; margin-bottom: 15px; }
                .code { background: #f3f4f6; padding: 3px 8px; border-radius: 4px; font-family: monospace; }
                a { color: #2563eb; text-decoration: none; font-weight: 600; }
            </style>
        </head>
        <body>
            <div class="error-box">
                <h1>‚ö†Ô∏è Simple Debate Arena Not Available</h1>
                <p>The Simple Debate Arena feature is not currently enabled on this server.</p>
                <p><strong>Required:</strong></p>
                <ul style="text-align: left; display: inline-block;">
                    <li>Set <span class="code">DATABASE_URL</span> environment variable in Render</li>
                    <li>Upload <span class="code">simple_debate_models.py</span> to project root</li>
                    <li>Upload <span class="code">simple_debate_routes.py</span> to project root</li>
                </ul>
                <p style="margin-top: 30px;"><a href="/">‚Üê Back to Home</a></p>
            </div>
        </body>
        </html>
        ''', 503
    return render_template('simple-debate-arena.html')

# ============================================================================
# API ROUTES - NEWS ANALYSIS
# ============================================================================

@app.route('/api/analyze', methods=['POST'])
def analyze_news():
    """
    Main endpoint for news article analysis.
    
    CRITICAL v10.2.10 FIX: Changed from /api/analyze-news to /api/analyze
    This matches what the frontend (unified-app-core.js) expects!
    """
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        url = data.get('url')
        article_text = data.get('text') or data.get('article_text')
        
        logger.info("=" * 80)
        logger.info("NEW ANALYSIS REQUEST:")
        logger.info(f"  URL provided: {bool(url)}")
        logger.info(f"  Text provided: {bool(article_text)}")
        logger.info("=" * 80)
        
        # Validate input
        if not url and not article_text:
            return jsonify({
                'success': False,
                'error': 'Either URL or article text must be provided'
            }), 400
        
        # Validate URL format if provided
        if url and not validate_url(url):
            return jsonify({
                'success': False,
                'error': 'Invalid URL format'
            }), 400
        
        # Analyze the article (pipeline will handle extraction with ArticleExtractor service)
        logger.info("Starting comprehensive analysis (pipeline will extract article)...")
        raw_results = news_analyzer_service.analyze(
            content=url or article_text,
            content_type='url' if url else 'text'
        )
        
        # Check if analysis succeeded
        if not raw_results.get('success'):
            error_msg = raw_results.get('error', 'Analysis failed')
            logger.error(f"Analysis failed: {error_msg}")
            return jsonify({
                'success': False,
                'error': error_msg
            }), 500
        
        logger.info("Analysis complete - transforming data...")
        
        # Transform the results using the correct method name
        final_results = data_transformer.transform_response(
            raw_data=raw_results
        )
        
        logger.info("Data transformation complete")
        logger.info("=" * 80)
        
        return jsonify({
            'success': True,
            'data': final_results
        })
        
    except Exception as e:
        logger.error("=" * 80)
        logger.error("ANALYSIS ERROR:")
        logger.error(f"Error: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        logger.error("=" * 80)
        
        return jsonify({
            'success': False,
            'error': f'Analysis failed: {str(e)}'
        }), 500

# ============================================================================
# API ROUTES - TRANSCRIPT ANALYSIS (v10.2.3)
# ============================================================================

# Store active jobs in memory (in production, use Redis or database)
transcript_jobs = {}
transcript_job_api = None

try:
    from services.transcript_analyzer import TranscriptAnalyzer
    transcript_job_api = TranscriptAnalyzer()
    logger.info("TranscriptAnalyzer initialized successfully")
except ImportError as e:
    logger.warning(f"TranscriptAnalyzer not available: {e}")
    transcript_job_api = None

@app.route('/api/youtube/process', methods=['POST'])
def process_youtube_transcript():
    """
    Process YouTube URL for transcript extraction and analysis
    NOW PROPERLY CREATES JOB_ID (v10.2.3 FIX)
    """
    try:
        if not transcript_job_api:
            return jsonify({
                'success': False,
                'error': 'Transcript analysis service not available'
            }), 503
        
        data = request.get_json()
        youtube_url = data.get('url')
        
        if not youtube_url:
            return jsonify({
                'success': False,
                'error': 'YouTube URL is required'
            }), 400
        
        logger.info(f"Processing YouTube URL: {youtube_url}")
        
        # Create a job and start processing
        job_id = transcript_job_api.create_job(youtube_url)
        
        logger.info(f"‚úÖ Created job_id: {job_id} for YouTube analysis")
        
        # Return immediately with job_id
        return jsonify({
            'success': True,
            'job_id': job_id,
            'message': 'Processing started',
            'status': 'processing'
        })
        
    except Exception as e:
        logger.error(f"YouTube processing error: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/youtube/status/<job_id>', methods=['GET'])
def get_youtube_job_status(job_id):
    """Check the status of a YouTube transcript analysis job"""
    try:
        if not transcript_job_api:
            return jsonify({
                'success': False,
                'error': 'Transcript analysis service not available'
            }), 503
        
        status = transcript_job_api.get_job_status(job_id)
        
        if not status:
            return jsonify({
                'success': False,
                'error': 'Job not found'
            }), 404
        
        return jsonify({
            'success': True,
            'status': status['status'],
            'data': status.get('data'),
            'error': status.get('error')
        })
        
    except Exception as e:
        logger.error(f"Job status error: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/youtube/create-transcript', methods=['POST'])
def create_youtube_transcript():
    """
    NEW v10.2.5: Create YouTube transcript WITHOUT full analysis
    Just extracts and formats the transcript for display/download
    """
    try:
        data = request.get_json()
        youtube_url = data.get('url')
        
        if not youtube_url:
            return jsonify({
                'success': False,
                'error': 'YouTube URL is required'
            }), 400
        
        logger.info(f"Creating transcript for YouTube URL: {youtube_url}")
        
        # Extract transcript using ScrapingBee
        result = extract_youtube_transcript(youtube_url)
        
        if not result['success']:
            return jsonify(result), 400
        
        logger.info(f"‚úÖ Transcript created successfully")
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"Transcript creation error: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/youtube/download-transcript-pdf', methods=['POST'])
def download_transcript_pdf():
    """
    NEW v10.2.5: Generate PDF from transcript data
    """
    try:
        from reportlab.lib.pagesizes import letter
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import inch
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
        from reportlab.lib.enums import TA_LEFT, TA_CENTER
        from io import BytesIO
        
        data = request.get_json()
        transcript_data = data.get('transcript_data')
        
        if not transcript_data:
            return jsonify({
                'success': False,
                'error': 'Transcript data is required'
            }), 400
        
        # Create PDF in memory
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=letter,
                              rightMargin=72, leftMargin=72,
                              topMargin=72, bottomMargin=18)
        
        # Container for PDF elements
        elements = []
        
        # Styles
        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=16,
            textColor='#1a202c',
            spaceAfter=30,
            alignment=TA_CENTER
        )
        
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontSize=12,
            textColor='#2d3748',
            spaceAfter=12,
            spaceBefore=12
        )
        
        body_style = ParagraphStyle(
            'CustomBody',
            parent=styles['Normal'],
            fontSize=10,
            textColor='#4a5568',
            spaceAfter=12,
            alignment=TA_LEFT
        )
        
        # Add title
        title = Paragraph(transcript_data.get('title', 'YouTube Transcript'), title_style)
        elements.append(title)
        elements.append(Spacer(1, 12))
        
        # Add metadata
        metadata_items = [
            ('Channel', transcript_data.get('channel', 'Unknown')),
            ('Duration', transcript_data.get('duration', 'Unknown')),
            ('Date Published', transcript_data.get('publish_date', 'Unknown'))
        ]
        
        for label, value in metadata_items:
            meta = Paragraph(f"<b>{label}:</b> {value}", body_style)
            elements.append(meta)
        
        elements.append(Spacer(1, 24))
        
        # Add transcript heading
        transcript_heading = Paragraph("Transcript", heading_style)
        elements.append(transcript_heading)
        elements.append(Spacer(1, 12))
        
        # Add transcript text
        transcript_text = transcript_data.get('transcript', '')
        # Split into paragraphs for better formatting
        paragraphs = transcript_text.split('\n\n')
        for para in paragraphs:
            if para.strip():
                p = Paragraph(para.strip(), body_style)
                elements.append(p)
                elements.append(Spacer(1, 12))
        
        # Build PDF
        doc.build(elements)
        
        # Get PDF data
        pdf_data = buffer.getvalue()
        buffer.close()
        
        # Return as base64 for frontend download
        import base64
        pdf_base64 = base64.b64encode(pdf_data).decode('utf-8')
        
        return jsonify({
            'success': True,
            'pdf_data': pdf_base64,
            'filename': f"transcript_{transcript_data.get('video_id', 'unknown')}.pdf"
        })
        
    except Exception as e:
        logger.error(f"PDF generation error: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ============================================================================
# HEALTH CHECK & DEBUG ROUTES
# ============================================================================

@app.route('/health')
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'services': {
            'news_analyzer': 'active',
            'transcript_analyzer': 'active' if transcript_job_api else 'disabled',
            'old_debate_arena': 'active' if old_debate_available else 'disabled',
            'simple_debate_arena': 'active' if simple_debate_available else 'disabled'
        }
    })

@app.route('/debug/api-keys', methods=['GET'])
def debug_api_keys():
    return jsonify({
        'anthropic': bool(os.getenv('ANTHROPIC_API_KEY')),
        'openai': bool(os.getenv('OPENAI_API_KEY')),
        'google_fact_check': bool(os.getenv('GOOGLE_FACT_CHECK_API_KEY')),
        'assemblyai': bool(os.getenv('ASSEMBLYAI_API_KEY')),
        'scrapingbee': bool(os.getenv('SCRAPINGBEE_API_KEY')),
        'database': bool(database_url)
    })

@app.route('/debug/static-files')
def debug_static_files():
    """Debug route to check static file configuration."""
    static_path = os.path.join(app.root_path, 'static')
    
    debug_info = {
        'app_root_path': app.root_path,
        'static_folder': app.static_folder,
        'static_url_path': app.static_url_path,
        'static_path_exists': os.path.exists(static_path),
        'static_contents': []
    }
    
    if os.path.exists(static_path):
        for root, dirs, files in os.walk(static_path):
            rel_root = os.path.relpath(root, static_path)
            for file in files:
                rel_path = os.path.join(rel_root, file) if rel_root != '.' else file
                debug_info['static_contents'].append(rel_path)
    
    return jsonify(debug_info)

@app.route('/static/<path:filename>')
def serve_static(filename):
    """Explicitly serve static files."""
    return send_from_directory(app.static_folder, filename)

# ============================================================================
# MAIN
# ============================================================================

if __name__ == '__main__':
    logger.info("=" * 80)
    logger.info("TRUTHLENS NEWS ANALYZER - STARTING v10.2.15")
    logger.info("=" * 80)
    logger.info("")
    logger.info("AVAILABLE FEATURES:")
    logger.info("  ‚úì News Analysis - 7 AI services with comprehensive fact-checking")
    logger.info("    - Source credibility analysis")
    logger.info("    - Bias detection (enhanced with outlet awareness)")
    logger.info("    - Fact-checking with multiple sources")
    logger.info("    - Author analysis (supports unknown authors)")
    logger.info("    - Transparency evaluation")
    logger.info("    - Content quality assessment")
    logger.info("    - Manipulation detection")
    logger.info("")
    
    if os.getenv('ASSEMBLYAI_API_KEY'):
        logger.info("  ‚úì Live Stream Analysis - YouTube Live with real-time transcription")
        logger.info("    - Real-time audio transcription (AssemblyAI)")
        logger.info("    - Automatic claim extraction")
        logger.info("    - Live fact-checking")
        logger.info("    - Server-Sent Events for updates")
    else:
        logger.info("  ‚úó Live Streaming - Disabled (set ASSEMBLYAI_API_KEY to enable)")
    
    if os.getenv('SCRAPINGBEE_API_KEY') and transcript_job_api:
        logger.info("  ‚úì YouTube Transcript Extraction - Video transcript analysis")
        logger.info("    - Extract transcripts from any YouTube video")
        logger.info("    - Automatic caption retrieval")
        logger.info("    - Comprehensive fact-checking with job management")
        logger.info("    - ‚úÖ FIXED: Now properly creates jobs and returns job_id")
    else:
        logger.info("  ‚úó YouTube Transcripts - Disabled (set SCRAPINGBEE_API_KEY to enable)")
    
    logger.info("  ‚úì NEW Debate Arena - Partner Mode & Pick-a-Fight (v4.2.0) ‚≠ê NEW")
    logger.info("    - Partner Mode: Private debates with share codes")
    logger.info("    - Pick-a-Fight: Public challenge system")
    logger.info("    - Live Debates: Real-time voting display")
    logger.info("    - Email authentication with verification")
    logger.info("    - 50-500 word argument limit")
    logger.info("    - My Debates: Track participation")
    logger.info("    - ‚úÖ FIXED v10.2.15: Route now properly renders debate-arena.html")
    logger.info("    - Available at /debate-arena")
    
    if simple_debate_available:
        logger.info("  ‚úì OLD Simple Debate Arena - Anonymous Debates (v10.2.6)")
        logger.info("    - Pick a Fight: Create debate and first argument")
        logger.info("    - Join a Fight: Add opposing argument")
        logger.info("    - Judgement City: Vote with bar chart")
        logger.info("    - No authentication required")
        logger.info("    - 250-word argument limit")
        logger.info("    - Browser fingerprint voting")
        logger.info("    - Available at /simple-debate-arena")
    else:
        logger.info("  ‚úó OLD Simple Debate Arena - Disabled (DATABASE_URL not set)")
    
    logger.info("")
    logger.info("STATIC PAGE ROUTES:")
    logger.info("  ‚úì / (News Analysis)")
    logger.info("  ‚úì /transcript (Transcript Analysis)")
    logger.info("  ‚úì /features (Features Page)")
    logger.info("  ‚úì /about (About Page)")
    logger.info("  ‚úì /contact (Contact Page)")
    logger.info("  ‚úì /live-stream (Live Stream Page)")
    logger.info("  ‚úì /debate-arena (NEW Debate Arena) ‚≠ê FIXED")
    logger.info("  ‚úì /simple-debate-arena (OLD Simple Debate Arena)")
    logger.info("")
    
    logger.info("VERSION HISTORY:")
    logger.info("NEW IN v10.2.15 (DEBATE ARENA ROUTE FIX) üéØ:")
    logger.info("  ‚úÖ CRITICAL FIX: Removed redirect from /debate-arena route")
    logger.info("  ‚úÖ FIXED: Route was redirecting to /simple-debate-arena")
    logger.info("  ‚úÖ FIXED: Now ALWAYS renders templates/debate-arena.html")
    logger.info("  ‚úÖ RESULT: Clicking 'Debate Arena' menu now loads correct page!")
    logger.info("  ‚úÖ RESULT: No more unwanted redirects to old simple arena")
    logger.info("  ‚úÖ PRESERVED: All v10.2.14 functionality (DO NO HARM)")
    logger.info("")
    logger.info("=" * 80)
    
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)

# I did no harm and this file is not truncated
# v10.2.15 - October 29, 2025 - Debate Arena route fix: no redirect, always render debate-arena.html
